# Cluster Network Model in Kubernetes

## What is the Kubernetes Cluster Network Model?

The **Kubernetes Cluster Network Model** defines the fundamental networking rules that every Kubernetes cluster must follow so that Pods, Services, and Nodes can communicate reliably—regardless of the underlying network plugin (CNI) or infrastructure.

This model is **not an implementation**. Instead, it is a **set of guarantees and assumptions** that Kubernetes makes, while leaving the actual networking implementation to CNI plugins such as Calico, Flannel, Cilium, Weave, etc.

---

## Core Networking Assumptions (The Golden Rules)

Kubernetes enforces **three mandatory rules**:

### 1. Pod-to-Pod Communication (Across Nodes)

* Every Pod gets its **own unique IP address**
* Any Pod can communicate with **any other Pod**
* Communication happens **without NAT**
* Pod IPs are routable across the entire cluster

**Implication:**

* A Pod on Node A can directly reach a Pod on Node B using its Pod IP

---

### 2. Node-to-Pod Communication

* Nodes can communicate with all Pods
* Pods can communicate with the Node they run on

**Used for:**

* kubelet → Pod
* Node-level agents (logging, monitoring)

---

### 3. Pod-to-Service Communication

* Services provide a **stable virtual IP (ClusterIP)**
* kube-proxy (or eBPF) handles traffic routing to backend Pods
* Pods access Services instead of directly accessing Pod IPs

---

## Addressing in the Cluster Network Model

### IP Address Types

| Entity  | IP Type   | Scope                                  |
| ------- | --------- | -------------------------------------- |
| Pod     | Pod IP    | Cluster-wide unique                    |
| Node    | Node IP   | Underlying network                     |
| Service | ClusterIP | Virtual (not routable outside cluster) |

---

## How Kubernetes Achieves This Model

Kubernetes itself does **not** configure networking. Instead, it relies on:

### 1. CNI (Container Network Interface)

* Responsible for:

  * Assigning Pod IPs
  * Creating network interfaces
  * Routing traffic between Pods

Examples:

* Calico
* Flannel
* Cilium
* Weave Net

---

### 2. kube-proxy

* Runs on every Node
* Implements Service networking
* Uses:

  * iptables
  * IPVS
  * eBPF (with advanced CNIs)

Responsibilities:

* Service → Pod load balancing
* ClusterIP, NodePort, LoadBalancer traffic

---

## Pod Networking Model (Inside a Node)

* All containers in a Pod:

  * Share the **same network namespace**
  * Share the same IP address
  * Can communicate via `localhost`

This enables:

* Sidecar patterns
* Init containers
* Tight container coupling

---

## Traffic Flow Examples

### Pod-to-Pod (Same Node)

* Uses Linux bridge or veth pairs
* No external routing involved

### Pod-to-Pod (Different Nodes)

* Traffic routed via:

  * Overlay networks (VXLAN, IP-in-IP)
  * Or native L3 routing (BGP)

Handled entirely by the CNI

---

### Pod-to-Service

1. Pod sends request to Service IP
2. kube-proxy intercepts traffic
3. Traffic forwarded to one of the backend Pods

---

## No-NAT Principle

A key design decision:

* **No NAT between Pods**
* Source IP is preserved

Benefits:

* Simplified debugging
* Better observability
* Cleaner security policies

---

## Network Policy and the Cluster Model

By default:

* All Pods can communicate with each other

NetworkPolicies:

* Add traffic restrictions
* Enforced by CNI plugins
* Operate at L3/L4 (and sometimes L7)

---

## What Kubernetes Does NOT Define

Kubernetes does **not** mandate:

* How packets are encapsulated
* Whether overlays or native routing are used
* Performance characteristics
* Encryption

These are **implementation details of the CNI**

---

## Full Traffic Flow Diagrams (End-to-End)

Below are **plain-text architecture diagrams** showing how traffic flows in a Kubernetes cluster. These are logical flows and apply regardless of the CNI implementation.

---

## 1. Pod → Pod (Same Node)

```
+---------------- Node A ----------------+
|                                        |
|  Pod A (10.244.1.10)                   |
|   └─ veth0                             |
|        │                               |
|        │  Linux Bridge / CNI bridge    |
|        │                               |
|   ┌─ veth1                             |
|  Pod B (10.244.1.11)                   |
|                                        |
+----------------------------------------+
```

### Flow Explanation

1. Pod A sends traffic to Pod B IP
2. Packet stays on the same node
3. Routed via veth pairs / Linux bridge
4. No kube-proxy, no NAT, no external routing

---

## 2. Pod → Pod (Different Nodes)

```
+------------------------ Node A ------------------------+     +------------------------ Node B ------------------------+
|                                                        |     |                                                        |
|  Pod A (10.244.1.10)                                   |     |                                   Pod B (10.244.2.15)  |
|        |                                               |     |                                               ^        |
|        |  veth (pod side)                              |     |                               veth (pod side) |        |
|        v                                               |     |                                               |        |
|  veth (host side)                                      |     |                              veth (host side) |        |
|        |                                               |     |                                               ^        |
|        v                                               |     |                                               |        |
|  CNI Datapath / Bridge                                 |     |                         CNI Datapath / Bridge          |
|        |                                               |     |                                               ^        |
|        |  route: 10.244.2.0/24                         |     |                                               |        |
|        v                                               |     |                                               |        |
|  Node A Network Stack                                  |     |                         Node B Network Stack           |
|        |                                               |     |                                               ^        |
|        |  encapsulate OR route                         |     |                       decapsulate OR route    |        |
|        |  (VXLAN / IPIP / BGP)                         |     |                                               |        |
|        +-------------------------------------------Underlay Network ----------------------->                          |
|                                                        |     |                                                        |
+--------------------------------------------------------+     +--------------------------------------------------------+

```

### Flow Explanation

1. Pod A sends packet to Pod B IP
2. Node A CNI encapsulates or routes packet
3. Packet traverses node-to-node network
4. Node B CNI decapsulates packet
5. Packet delivered directly to Pod B

---

## 3. Pod → Node (Accessing Node Services)

```
+---------------- Node ----------------+
| Pod A (10.244.1.10)                  |
|    │                                 |
|    │                                 |
|    ▼                                 |
| Node IP (192.168.1.10)               |
|   ├─ kubelet (10250)                 |
|   ├─ node exporter                   |
|   └─ local services                  |
+-------------------------------------+
```

### Flow Explanation

1. Pod sends traffic to Node IP
2. Routed via node routing table
3. No kube-proxy involved
4. Used by monitoring, logging, kubelet access

---

## 4. Node → Pod (Control Plane / kubelet Path)

```
+-------------- Control Plane --------------+
| kube-apiserver                             |
+------------------▲------------------------+
                   │
                   │
+------------------┼------------------------+
| Node IP                                   |
|   │                                       |
|   ▼                                       |
| kubelet                                   |
|   │                                       |
|   ▼                                       |
| Pod (10.244.1.10)                         |
+-------------------------------------------+
```

### Flow Explanation

1. Control plane communicates with Node IP
2. kubelet manages Pod lifecycle
3. Node routes traffic to Pod network

---

## 5. Pod → Service (ClusterIP)

```
+------------- Pod A ----------------+
| curl http://my-service             |
|        │                           |
|        ▼                           |
| Service IP (10.96.0.20)            |
|        │                           |
|   kube-proxy (iptables/IPVS)       |
|        │                           |
|        ▼                           |
| Pod B / Pod C (Endpoints)          |
+-----------------------------------+
```

### Flow Explanation

1. Pod sends request to Service ClusterIP
2. kube-proxy intercepts traffic
3. Destination Pod selected
4. Packet forwarded to backend Pod

---

## 6. External → NodePort → Pod

```
Client
  │
  ▼
Node IP:30080
  │
  ▼
kube-proxy
  │
  ▼
Pod (TargetPort)
```

### Flow Explanation

1. External client hits Node IP + NodePort
2. kube-proxy routes traffic
3. Request forwarded to Pod

---

## Key Observations Across All Flows

* Pod IPs are **cluster-wide routable**
* No NAT between Pods
* kube-proxy only involved in **Service traffic**
* CNIs handle **Pod networking and routing**
* Kubernetes defines the model, not the packet mechanics

---

## Summary

The Kubernetes Cluster Network Model ensures:

* Flat Pod network
* Direct Pod reachability
* Predictable Service abstraction
* Infrastructure-agnostic networking

These guarantees allow applications to behave the same way across all Kubernetes clusters.
